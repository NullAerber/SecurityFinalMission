\section{未来工作}
\begin{enumerate}
    \item 虽然通过Kmeans降维之后SVM的检测方法有所提高，但是基于SVM的恶意URL检测很依赖于训练数据集，有必要保证原始数据集尽可能的减少噪点（离群值），以及每条数据之间尽可能的减少关联性。所以若能拿到现实生活中确定正常或者威胁的请求数据作为训练数据集的补充，来对检测模型进行优化，效果应该会更好。
    \item 对于基于逻辑回归的检测方法，使用降维之后，正确率不升反降，说明降维这个方法并不是lg的优化策略，因为可以考虑寻找对lg方法进行优化的算法。 
    \item 在寻找数据的时候发现，白样本（正常访问URL）的数据量远大于比黑样本（恶意URL）的数据量，也就是出现了数据不平衡的问题（Imbalance Data），经过文献查找，这是属于relativ imbalanced，即负例数量足够多，但相对于正例，负例相对较少。H He，EA Garcia在2009年[p]提出相关一系列的针对数据的解决方案，例如取样方法，将不平衡数据通过某些方法变成平衡数据；代价敏感方法；数据合成等，这样可以降低正反两种数据数据量之间的差距，从而提高正确率。
    \item 对于不平衡数据，我们还可以使用Positive and Unlabeled Learning（PU Learning）PU-Learning[p]是半监督学习的一种特殊情况[p]，它用于解决只提供正例和未标注样本而不提供负例的问题。可以考虑通过单分类模型，学习单类样本的最小边界，边界之外的则识别为异常。简单的讲，就是放弃学习攻击的URL特征，不如直接学习正常URL的特征，拒绝所有不符合正常特征的URL。 
\end{enumerate}
